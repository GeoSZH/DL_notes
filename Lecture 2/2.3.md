## Error surface is rugged
### Tips for training:Adaptive learning rate
#### critical points不是我们训练中的最大阻碍？

![image](https://user-images.githubusercontent.com/88269254/170855719-13603eb0-e57e-4564-8df1-915cd2d67c0d.png)

如上图所示的情况，上面为loss，下面为gradient，横轴则为迭代次数，我们可以明显的看出来，在loss不再下降的时候，我们有可能是因为卡在如图左所示的情况之中，所以loss没法再下降并不一定是卡在了local minima或是saddle point，而有可能是因为梯度和学习率的原因，loss没有办法再下降了。

![image](https://user-images.githubusercontent.com/88269254/170855842-233dbc96-ef88-417f-bd7e-7653556252fd.png)

我们以前展示过这个图，通过走到critical points然后判断Hessian矩阵特征值的比例然后来判断我们走到local minima其实很难，大多数都是saddle points，但是我们回过来看这张图，我们当时说的是训练到loss不再减小的时候，但那真的是critical points吗？不一定，不过这个图是通过特殊方法训练的，所以确实是critical point。在我们实际的应用过程中，往往我们还没有到达critical points，只是到那附近的时候，我们的loss就会不再减小，从而train不起来了。所以我们在用gradient descent的方法来optimization的时候，我们应该优先注意的是不要让train中止在还没到达critical points的地方。

![image](https://user-images.githubusercontent.com/88269254/170856136-354003d1-9a60-466b-8a2d-e380207bc5b5.png)

我们可以看到如图右上所示，当我们做gradient descent的时候，我们的学习率设的稍微大一点点，图左下我们用的0.01，就出现了我们前面提到的情况，他会在两边不断震荡从而无法收敛，这时候我们肯定是调小learning rate，如图右下，我们调小了learning rate，更新参数的步伐变小了，但是我们b方向的参数更新又太慢了，由于学习率太小，我们甚至更新了10W次，还是离终点很远，所以这时候我们需要自适应学习率，也就是自定义学习率，每个参数都设置不同的学习率。

![image](https://user-images.githubusercontent.com/88269254/170856362-214d2716-9869-41c9-840e-6fc0fe42508d.png)

我们肯定是希望在比较平坦的地方用较大的学习率，而在比较陡峭的地方用较小的学习率，所以我们需要在原来的gradient descent的式子里再学习率η下方添加一个σ，我们可以看到它既有一个下标i还有一个上标t，也就是说我们在不同的参数之间有不同的σ，在不同的迭代轮次中也是一样！

#### σ一般是怎么取值呢？
![image](https://user-images.githubusercontent.com/88269254/170856832-a274fe40-f174-48d7-bb81-36208eed089c.png)

如上图所示，我们用之前所有梯度的平方和的平均的算术平方根来作为σ的取值，在下图的实例中也展现了它的威力，我们在下图的右上中可以看到，gradient较小的时候，我们σ也较小，然后学习率η除上一个较小的值，就会比原来大，而在右下中，gradient较大，σ也较大，我们得到了一个比原来较小的学习率，所以我们的目的得以实现，这个方法用在Adagrad里面。

![image](https://user-images.githubusercontent.com/88269254/170856840-f80af3c0-8ee3-412d-94cc-42bbc46d1826.png)

但是这并不是我们想要的终极版本，因为上图的假设比较理想化，gradient一直维持在一个较小或者较大的值，但是当gradient有大有小的时候，势必会对我们的σ有所影响，如下图所示，我们想要在同一个参数的不同阶段也要能够动态的调整学习率：

![image](https://user-images.githubusercontent.com/88269254/170857062-9304bae0-b28a-48cf-8a3c-1db237685c84.png)

解决办法也有：RMSProp，我们可以定义一个超参数α，让它来决定之前计算的σ是否重要，从而自适应的改变，见下图：

![image](https://user-images.githubusercontent.com/88269254/170857223-c8b389f8-2caa-4a22-a242-e14d65742b03.png)

实际应用中，我们可以通过对α的调整，从而改变σ的值，进而调整学习率，从而实现我们“**踩刹车**”或者“**加速**”。

![image](https://user-images.githubusercontent.com/88269254/170857327-c0a8b850-a905-4486-be75-f016ae59ade6.png)

我们今天训练神经网络是的参数有一项是optimization，而我们比较常用的**Adam=RMSProp+Momentum**。Adam还有更多细节可以挖掘，具体可见pytorch中的代码或者文章：

![image](https://user-images.githubusercontent.com/88269254/170857455-32017ff5-5928-4ac8-a579-6b5cce034b77.png)

#### 实际效果
![image](https://user-images.githubusercontent.com/88269254/170857537-eba32750-bad3-4a35-beb3-0b0898357e56.png)

我们用RMS的方法来更新我们最开始举得例子，然后我们就会发现最开始是朝着一切顺利的方向发展的，但是后来忽然就爆炸了又正常了，反复几次逐渐接近终点，其实想想也应该可以理解，因为最开始我们的梯度较大，我们得到一个大的σ，然后学习率变小，而我们正是需要一个小的学习率，然后我们稳步向前走，在横向梯度较小时，我们逐渐训练，σ也会跟着变小起来，然后学习率会变大，从而向终点正常逼近，但是突然有一刻，我们积累的小的梯度太多了，所以就会震荡一下，然后又回到了较大梯度，由于σ的原因，我们又会逐渐回归正轨，最终反复几次。

#### Learning rate Scheduling
##### Learning rate decay
像我们上面提到的，其实我们可以想一个办法来解决，也就是Learning rate decay，我们让学习率随着时间（或者迭代轮次）逐渐减小，因为我们最开始离终点很远，所以会需要较大的学习率来更新参数，而在最后训练快要完成时，我们只需要较小的学习率即可，如下图：

![image](https://user-images.githubusercontent.com/88269254/170857886-cc1bd97d-e187-4166-a487-e61f4e909518.png)

##### Warm up
这里李宏毅老师提的另一种Learning rate Scheduling的方法就是warm up，这个在BERT或者Transformer中都有用到，而且在一些几年前的文章中也可以看到warm up的影子，具体是为什么？还没有明确的论文给出解释，有一个可能性就是我们最开始训练的时候可能σ并不是那么的可靠，所以我们需要一个较小的学习率让它探索一下，保证不要出事，然后再逐步增大，最后减小这样。

![image](https://user-images.githubusercontent.com/88269254/170858156-6d788a80-9ba6-4f00-8777-2757b8b3d556.png)

还可以参考如下的文章和warm up版本的Adam：RAdam

![image](https://user-images.githubusercontent.com/88269254/170858275-f281844a-1ab3-4a24-817a-2a155180428d.png)

![image](https://user-images.githubusercontent.com/88269254/170858279-0347df8f-7541-4986-bc82-c74756339a52.png)

## Summary of Optimization
我们可以看到我们之前接触的一般的gradient descent是下图中上方的，逐渐学习之后，我们的Gradient descent就变成了下方的样子，既有Momentum又有σ又有Learning rate Scheduling，这里有一个问题就是，Momentum回合σ相互抵消吗？其实并不会，因为Momentum虽然考虑整体的Gradient，但它考虑了方向，而σ则是Gradient的RMS，所以并不会相互抵消，各有各的作用！

我们现在所接触的Optimization及基本都是我们所介绍的最终形式，虽然细节上可能有所不同，但是最终都是回事重要的三个元素：**Momentum，σ，Learning rate Scheduling**

![image](https://user-images.githubusercontent.com/88269254/170858344-775bb5fd-b921-42d2-952f-de74589f0df3.png)

