## Error surface is rugged
### Tips for training:Adaptive learning rate
#### critical points不是我们训练中的最大阻碍？

![image](https://user-images.githubusercontent.com/88269254/170855719-13603eb0-e57e-4564-8df1-915cd2d67c0d.png)

如上图所示的情况，上面为loss，下面为gradient，横轴则为迭代次数，我们可以明显的看出来，在loss不再下降的时候，我们有可能是因为卡在如图左所示的情况之中，所以loss没法再下降并不一定是卡在了local minima或是saddle point，而有可能是因为梯度和学习率的原因，loss没有办法再下降了。

![image](https://user-images.githubusercontent.com/88269254/170855842-233dbc96-ef88-417f-bd7e-7653556252fd.png)

我们以前展示过这个图，通过走到critical points然后判断Hessian矩阵特征值的比例然后来判断我们走到local minima其实很难，大多数都是saddle points，但是我们回过来看这张图，我们当时说的是训练到loss不再减小的时候，但那真的是critical points吗？不一定，不过这个图是通过特殊方法训练的，所以确实是critical point。在我们实际的应用过程中，往往我们还没有到达critical points，只是到那附近的时候，我们的loss就会不再减小，从而train不起来了。所以我们在用gradient descent的方法来optimization的时候，我们应该优先注意的是不要让train中止在还没到达critical points的地方。

![image](https://user-images.githubusercontent.com/88269254/170856136-354003d1-9a60-466b-8a2d-e380207bc5b5.png)

我们可以看到如图右上所示，当我们做gradient descent的时候，我们的学习率设的稍微大一点点，图左下我们用的0.01，就出现了我们前面提到的情况，他会在两边不断震荡从而无法收敛，这时候我们肯定是调小learning rate，如图右下，我们调小了learning rate，更新参数的步伐变小了，但是我们b方向的参数更新又太慢了，由于学习率太小，我们甚至更新了10W次，还是离终点很远，所以这时候我们需要自适应学习率，也就是自定义学习率，每个参数都设置不同的学习率。

![image](https://user-images.githubusercontent.com/88269254/170856362-214d2716-9869-41c9-840e-6fc0fe42508d.png)

我们肯定是希望在比较平坦的地方用较大的学习率，而在比较陡峭的地方用较小的学习率，所以我们需要在原来的gradient descent的式子里再学习率η下方添加一个σ，我们可以看到它既有一个下标i还有一个上标t，也就是说我们在不同的参数之间有不同的σ，在不同的迭代轮次中也是一样！

