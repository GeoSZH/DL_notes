## Tips for training
### Batch
为什么要用**batch**？
首先我们update parameters和计算Loss都是基于每一个batch来的，1 **epoch** = sell all the batches once，然后我们会 **Shuffle** after each epoch。

#### Batch size
我们应该怎么挑选batch size？举两个比较极端的例子，一个是**full batch**，另一个**batch size=1**，如下图：

![image](https://user-images.githubusercontent.com/88269254/170849300-ea8c3330-4c08-4e50-9fff-d3be4176789e.png)

也正如图上所标注的，我们可以看到，当batch size较大的时候，参数更新是比较缓慢的，但很稳定，而batch size较小的时候，甚至每一个样本都更新一次参数，这样虽然更新快，但不稳定。那到底是哪个比较好？

其实在计算效率上，可能batch size较大的一方效率更高，因为GPU的飞速发展，并行计算带来了很大的收益，比较如下：

![image](https://user-images.githubusercontent.com/88269254/170849406-e39fb401-6ba8-42f1-a35c-15a8c60d532a.png)

那看起来Batch size较大比较合适，现在有计算效率和更新参数稳定两个优点，但是，实际运用中noisy的gradient反而可以帮助training，也就是说在batch size较小的时候acc更高一点，具体可以见下图：同一个模型

![image](https://user-images.githubusercontent.com/88269254/170849532-85db6bb5-7f11-47ca-a6e2-2e1bc7de27f9.png)

batch size大小不同在**validation set**上面的acc表现可能与我们的直觉不太相同，是什么原因呢？这个是**overfitting**吗？首先肯定不是overfitting，我们发现batch size较大的时候training set的acc也跟着降了下来，所以肯定不是**overfiting**。又因为我们用的是同一个模型，所以可以排除**Model bias**，所以应该是**optimization**问题，大的batch size可能optimization有问题，而小的batch size optimization结果是比较好的。这里有一个可能的解释就是，我们计算loss时每个batch都不一样，函数也不同，所以不容易被卡在**local minima**（**critical point**）上，具体可见下图：

![image](https://user-images.githubusercontent.com/88269254/170849643-e2015a71-7299-4e3d-b361-b6a46dcb8d5a.png)

可能这里会有人质疑，假如说解决了optimization的问题，那么大的batch size是不是可能会比小的表现更好呢？也有人做了相关的实验控制变量来验证到底是小的batch好还是大的batch好一点，结果发现，小的batch size竟然在**testing data**上面表现也更好！实验如下图：

![image](https://user-images.githubusercontent.com/88269254/170849788-eddf68d5-e15b-4ca0-a690-c23e7b33b95d.png)

那么这到底是为什么呢？这里首先要介绍一下local minina的“**好坏**”之分，我们一般情况下认为如果在一个宽阔的盆地形状的local minima是好的，而在一个窄的峡谷里面的local minima则是坏的，为什么这样判断？我们做一个假设，因为testing set和training set一般都是从一个样本集中sample出来的，所以有的时候不一定分布完全相同，会有一些些许的差异，这时候就会像图中所示testing loss虽不能保证和traing loss的曲线完全一致，但是也应该是接近的。但就是在这种情况下，好的和坏的local minima的差距就体现出来了！我们发现这种情况下，好的local minima可以保证其准确性不偏离很多，但是坏的local minima则是影响很大。而一般情况下，人们趋向于认为大的Large batch是更容易进到峡谷里面，这点我们在上面的介绍中也可以看出来，因为小的batch size更新参数具有随机性，所以遇到小的峡谷一般更加容易跳出来，而大的batch size更容易陷在峡谷之中。**要注意这只是一个解释，不一定是完全正确的，也没有严格证明，所以在实际的模型训练中，可以多尝试，比较看哪一种效果更好。**

![image](https://user-images.githubusercontent.com/88269254/170849941-c56797c2-c4ad-4f14-9326-368d4980333a.png)

最后来一个小的batch和大的batch之间的比较表格：

![image](https://user-images.githubusercontent.com/88269254/170849978-9c232043-1452-40c9-843e-dddc7e8a4c32.png)

那么二者的优点是否可以兼顾？这里有李宏毅老师给了几篇文章，都是batch size较大并且想办法弥补了batch size较大的劣势，可以参考：

![image](https://user-images.githubusercontent.com/88269254/170850035-8361055f-ec2a-4b35-93bb-e0db85aa2f32.png)

### Momentum
这是另一个可能解决saddle point的方法，也就是我们模拟现实世界中的动量，给参数更新加上一个趋势，使他在平坦的saddle point和一些local minima能够继续更新，如图：

![image](https://user-images.githubusercontent.com/88269254/170850292-2b2f8512-fd6c-49f2-9a61-286b5c955390.png)

下面再来两个加上动量前后的比较，我们一般式根据梯度的反方向来更新参数的，这是未加的：

![image](https://user-images.githubusercontent.com/88269254/170850309-dbc32ced-a5b9-4845-a49d-3998a610c2e7.png)

这是加上动量之后，我们发现之前的梯度一直对后面的产生着影响：

![image](https://user-images.githubusercontent.com/88269254/170850330-63a2b715-1f75-44c4-9f4d-12459433a2f6.png)

这里李宏毅老师给了一个更容易明白的例子。我们看到图中我们越过了平坦的点甚至越过了一个local minima：

![image](https://user-images.githubusercontent.com/88269254/170850363-864ae77a-83c7-450f-855b-473556a6329e.png)

最后是一个小的总结：

- critical points的梯度为0
- critical points既有可能是saddle points也可能是local minima
  - 可以通过Hessian矩阵来判断
  - 可以通过Hessian矩阵的特征向量的方向来逃离saddle points
  - local minima可能没我们想象的那么多
- 小的batch size和动量也可以帮助我们逃离critical points
